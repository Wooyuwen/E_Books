# 分布式系统



### 分布式系统挑战：异构性

> 中间件：软件层：编程抽象，屏蔽底层网络、硬件、操作系统和编程语言的异构性。
>
> - 公共对象请求代理
> - JAVA远程调用方法
>
> 大多数中间件基于互联网协议实现，屏蔽了底层网络的差异，需要解决操作系统和硬件的不同。

### 分布式系统挑战：开放性

> 能否以不同的方式被扩展和重新实现
>
> 特点：
>
> > - 发布系统的关键接口开放系统的特征
> > - 基于一致的通信机制和发布接口访问共享资源
> > - 能用异构硬件和软件构造

### 分布式系统挑战：安全性、透明性、并发性、故障处理、可伸缩性

> 机密性、完整性、可用性
>
> 拒绝服务攻击
>
> 移动代码的安全性



复制集之间的数据复制

> 同步：保证数据一致性，容易导致延迟过高
>
> 异步：数据一致性不乏保证，容易读取过期数据
>
> 链式：根据路由和 TTL 来判定下一个需要同步的节点
>
> 主从：多个副本同时同步，需要大量带宽



### Raft一致性协议

> **强一致性**：让一个分布式系统看起来只有一个数据副本，并且读写操作都是原子的，任何时刻用户或节点都可以读到最近一次成功提交的副本数据
>
> **共识算法** ( Consensus Algorithm )：保证即使在小部分节点故障的情况下，系统仍能正常对外提供服务 ( P )，基于状态复制机模型  ( Replicated State Machine ) ，所有节点从同一个 state 出发，**经过同样的操作 log** ，最终达到一致的 state 。
>
> **Quorum** 机制来实现共识和容错，Raft 集群的操作称为提案，每当发起一个提案，需要 >N/2 节点同意才能 commit，该协议本身为 C 和 A 之间权衡，
>
> - 传统的WARO ( write all read one )：牺牲更新服务的可用性，最大程度增强读服务的可用性，写全部，读一个。
>
> - Quorum进行折中，写W个，读R个，W+R>N，这样保证一定能读到更新的数据
>
> ##### 节点分类：
>
> **Leader**：客户端对集群发起的所有操作必须由主节点进行处理
>
> **Follower**：请求的被动更新者，从leader接收更新请求，写入本地文件
>
> **Candidate**：如果follower在一定时间内没有收到leader的心跳，则判断leader可能已经故障，此时启动 leader election 过程，本节点切换为candidate直到选主结束
>
> **任期**：每一次新的选举为一个任期，每一次选举对应一个term号
>
> 节点之间通过RPC来通信：
>
> > - `RequestVote RPCs`：用于candidate拉票选举
> > - `AppendEntries RPCs`：用于leader向其他节点复制日志以及同步心跳
>




#### 节点状态转换过程（选主逻辑）
>
>> ![image-20211029194205544](C:\Users\wywfd\AppData\Roaming\Typora\typora-user-images\image-20211029194205544.png)
>> **raft选主基于心跳机制**，集群中每个节点刚启动时都是follower身份，如果一个时间段内没有收到任何心跳，也即选举超时，则会主观认为系统中没有可用的leader，并发起新的选举 ( Step: times out, starts election )
>>
>> 超时时间设置：每个节点的“超时时间”在一定范围内随机生成，降低大量节点同时发起选举的可能性。
>



#### 日志复制（保证log的一致性）
>
>> 共识算法：基于状态复制机模型，**raft负责保证集群中所有节点log的一致性**
>
>整体流程解析：leader接收客户端的请求，向其他节点发送 `AppendEntries RPC`，来要求它们将这条日志附加到各自本地的日志集合。当超过 (N/2+1) 节点已经复制后， leader 会将该日志 apply 到它本地的状态机中（**该日志为committed**），然后把操作成功的结果返回给客户端，raft保证`commited`的日志都会被持久化（参考`mysql`两段提交协议？）
>
>
>
>**日志一致性的保证**
>
>日志条目 ( term , index )，raft保证如果不同节点日志集合中的两个日志拥有相同的 term 和 index， 那么一定存储了相同的指令 
>
>
>
>**raft 要求 leader 在一个 term 内针对同一个 index 只能创建一条日志，并且永远不会修改它**
>
>
>
>raft 保证如果不同的节点日志集合中的两个日志条目拥有相同的 term 和 index，那么它们之前的所有日志条目也都相同，因为 leader 发出的 `AppendEntries RPC `中会额外携带上一条日志的 ( term, index )，如果 follower 在本地找不到相同的 ( term , index ) 日志，则**拒绝接收这次新的日志**。
>
>
>
>**raft中可能出现日志不一致场景**：
>
>解决宕机时一致性问题：
>
>​	follower 可能 缺少日志、多了未提交的日志、缺少日志又多了未提交日志
>
>
>
> follower 不可能比 leader 多出一些已提交日志:`AppendEntries RPC`一致性检查
>
>
>
> 如何处理日志不一致：**Raft 强制要求 follower 必须复制 leader 的日志集合来解决不一致问题**
>
>
>
>如何保持日志一致：**Leader 针对每个 follower 都维护一个 next index**，表示下一条需要发送给该follower 的日志索引：确定主从节点间同步的索引位置（主键减小）



#### 安全性问题

> **选举限制**：防止新leader同步产生可能的错误，限制选举资格
>
> **每个 candidate 必须在 `RequestVote RPC` 中携带自己本地日志的最新 (term, index)，如果 follower 发现这个 candidate 的日志还没有自己的新，则拒绝投票给该 candidate**
>
> 保证能赢得选举的candidate一定拥有所有的committed日志
>
> 
>
> **提交限制**：leader可能会覆盖之前leader提交的记录
>
> **Leader 只允许 commit 包含当前 term 的日志**：防止之前任期提交的记录被中间其他term高的Leader给覆盖掉



### 分布式锁

> **Zookeeper**：瞬时有序节点，安全性高，可持久化
>
> **Memcached**：并发高效
>
> **Redis**：
>
> - lua脚本保证原子性：执行脚本时，不会执行其他脚本（打断）或者redis命令。
> - RMW操作作为一个原子 操作执行，对整个过程进行加锁，INCR/DECR/SETNX命令将RMW三个操作转换为一个原子操作

