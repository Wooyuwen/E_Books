# 数据库



## Mysql



### 预读

> 数据库把请求交给文件系统
>
> 放入请求队列中
>
> 相关进程从请求队列中将请求读出
>
> 根据需求到相关数据区(内存\磁盘)读取数据
>
> 取出的数据放入响应队列中,最后数据库从相应队列中将数据取走
>
> 进程继续处理请求队列(如果是全表扫描,队列一般会满),判断后面几个数据请求的数据是否相邻来进行**预读**并将读请求合并
>
> `Innodb`预读:
>
> - 线性预读:区为单位
> - 随机预读:页为单位,着眼于将当前区中剩余的页提前读取到buffer pool中
>
> 



### MyISAM

> 1>.InnoDB支持事物，而MyISAM不支持事物
>
> 2>.InnoDB支持行级锁，而MyISAM支持表级锁
>
> 3>.InnoDB支持MVCC, 而MyISAM不支持
>
> 4>.InnoDB支持外键，而MyISAM不支持
>
> 5>.InnoDB不支持全文索引，而MyISAM支持



### 视图

> - 简化复杂的 SQL 操作，比如复杂的连接；
> - 只使用实际表的一部分数据；
> - 通过只给用户访问视图的权限，保证数据的安全性；
> - 更改数据格式和表示



### Innodb特性

> **插入缓冲**：insert buffer，物理页的一个组成部分，后变为changebuffer
>
> **二次写**：数据页可靠性，脏页不直接写入磁盘，先写入doublewritebuffer，再分两次写到共享数据页，最后fsync()
>
> **自适应哈希**：
>
> **异步IO**：
>
> **刷新邻接页**：将同一区域的页也刷新，存在的问题：不怎么脏刷完后立马变脏页



### 索引InnoDB

> 自适应哈希索引，全文索引
>
> innodb（B+树）：聚集索引：主索引和辅助索引
>
> 存储：索引组织文件，ibd-段(对应一个索引)-区(1MB)-页(16kb)
>
> **优点**：
>
> **缺点**：不能随意修改主键值
>
> 
>
> **页合并**：
>
> ​	删除一行记录只是被标记为删除并且它的空间允许被其他记录声明使用，当页中删除的记录达到MERGE_THRESHOLD（默认页体积的50%），InnoDB会开始寻找最靠近（前或后）的页进行合并以优化空间使用
>
> **页分裂**：
>
> ​	当前页装不下需要插入的记录，且下一页已满，则
>
> 1. 创建新页
> 2. 判断当前页可以从哪里进行分裂（记录行层面）
> 3. 移动记录行
> 4. 重新定义页之间的关系
>
> 可能会导致页中的数据分配到不同区中
>
> 页分裂合并会对索引树加写锁(x-latch)
>
> 辅助索引：
>
> > 为什么data域存主键值：一致性+节省内存空间，减少了移动数据页或者页分裂时二级索引的维护
>
> 回表查询
>
> 建索引的几大原则：
>
> > - 最左前缀
> > - = 和in可以乱序，在最左前缀中
> > - 尽量选择区分度高的列作为索引count(distinct col)/count(*)
> > - 索引不参与计算
> > - 尽量扩展索引，不建新索引
> > - 索引不能有null值



#### 最左前缀

> `EXPLAIN`中的字段：
>
> **1.type**：**联接类型。下面给出各种联接类型,按照从最佳类型到最坏类型进行排序:（重点看ref,rang,index）**
>
> 　　　　system：表只有一行记录（等于系统表），这是const类型的特例，平时不会出现，可以忽略不计
> 　　　　const：表示通过索引一次就找到了，const用于比较primary key 或者 unique索引。因为只需匹配一行数据，所有很快。如果将主键置于where列表中，mysql就能将该查询转换为一个const
> 　　　　eq_ref：唯一性索引扫描，对于每个索引键，表中只有一条记录与之匹配。常见于主键 或 唯一索引扫描。
> 　　　　注意：ALL全表扫描的表记录最少的表如t1表
> 　　　　**ref**：非唯一性索引扫描，返回匹配某个单独值的所有行。本质是也是一种索引访问，它返回所有匹配某个单独值的行，然而他可能会找到多个符合条件的行，所以它应该属于查找和扫描的混合体。
> 　　　　**range**：只检索给定范围的行，使用一个索引来选择行。key列显示使用了那个索引。一般就是在where语句中出现了bettween、<、>、in等的查询。这种索引列上的范围扫描比全索引扫描要好。只需要开始于某个点，结束于另一个点，不用扫描全部索引。
> 　　　　**index**：Full Index Scan，index与ALL区别为index类型只遍历索引树。这通常为ALL块，应为索引文件通常比数据文件小。（Index与ALL虽然都是读全表，但index是从索引中读取，而ALL是从硬盘读取）
>
> a c：走联合索引中的索引a，
>
> b：全索引扫描，不走联合索引



### 事务

> 满足ACID特性的一组操作，commit提交事务，或者rollback进行回滚
>
> A(Atomicity)：原子性，事务所有操作要么全部提交成功，要么全部失败回滚，回滚可查看混滚日志(Undo Log)来实现，其记录着事务所执行的修改操作，在回滚时反向执行这些修改操作即可。
>
> C(Consistency)：执行前后都保持一致性状态，所有事务读取结果相同。
>
> I(Isolation)：一个事务所做的修改在最终提交前，对其他事务是不可见的。
>
> D(Durability)：一旦事务提交，所作修改会永远保存在数据库中，即使系统发生崩溃，事务执行的结果也不能丢失。如若系统奔溃，可以用重做日志(Redo Log)进行修复，从而实现持久性。其为对数据页的物理修改。



### 并发一致性问题

> 丢失修改
>
> 读脏数据
>
> 不可重复读
>
> 幻影读
>
> 原因：没有完全实现隔离性AID-C



### 封锁

> MySQL：两种封锁粒度：**行级锁**和**表级锁**
>
> 封锁粒度越小，系统开销越大
>
> 封锁粒度越小，系统并发度越高
>
> 常用行级锁：`for update`
>
> > - 独占锁，执行提交后释放锁，悲观锁
> >
> > - select...for update，如果查询条件带主键，会锁行数据，如果没有，锁表
> >
> > - 仅支持InnoDB，且必须在事务处理模块(BEGIN/COMMIT)中才能生效(begin;/**/;commit;)
>
> ##### 封锁类型：
>
> > 1读写锁：互斥锁X写锁、共享锁S读锁
> >
> > 2意向锁：更容易地支持多粒度封锁，相比读写锁增加了IX/IS表锁
>
> ##### 封锁协议：
>
> > 1三级封锁协议
> >
> > - 一级封锁协议：事务 T 要修改数据 A 时必须加 X 锁，直到 `T 结束`才释放锁。
> >
> >   --解决修改丢失问题
> >
> > - 二级封锁协议：在一级基础上，要求读取数据 A 时必须加 S 锁，`读取完`马上释放 S 锁 。 
> >
> >   --解决读脏数据的问题
> >
> > - 三级封锁协议：前两级基础上，要求读取数据 A 时必须加 S 锁，直到`事务结束`才能释放 S 锁。        
> >
> >   --解决不可重复读问题
> >
> > 2 两段锁协议
> >
> > - 加锁和解锁分两个阶段进行
> >
> > -  可串行化调度：通过并发控制，使得并发执行的事务结果与某个串行执行的事务结果相同。
> > - 事务遵循两段锁协议是保证可串行化调度的充分条件。
>
> ##### MySQL隐式与显式锁定
>
> > InnoDB采用两段锁协议，所有锁在同一时刻释放，隐式锁定



### 隔离级别

>未提交读：事务中的修改，即使没有提交，对其他事务也可见
>
>提交读：只能读提交的修改，隔离性
>



### 行式存储

> 适用场景：
>
> - 随机的增删改查
> - 在行中选取所有属性的查询操作
> - 频繁插入或更新的操作，其操作与索引和行的大小更相关
>
> 劣势：读取目标涉及少数几项属性，但是需要读取一条完整的行记录----加索引，表分区。



###　列式存储

> 数据仓库和分布式数据库：从各个数据源汇总数据进行分析和反馈，大多围绕同一列数据进行
>
> 列式数据库可以在内存中高效组装各列的值，最终形成关系记录集，因此可以显著减少IO消耗。
>
> 适用场景：
>
> - 查询过程中，可以针对各列的运算并发执行(SMP)，最后在内存中聚合完整记录集，最大可能降低查询相应时间。
> - 可在数据列中高效查找数据，无需维护索引(任何列都能作为索引)，查询过程中能够尽量减少无关IO
> - 各列独立存储，数据类型已知，可以针对该列的数据类型、数据量大小等因素动态选择压缩算法。
>
> 不适用场景：
>
> - 数据需要频繁更新的交易场景
> - 表中列属性较少的小量数据库场景
> - 不适合做含有删除和更新的实时操作



### Mysql表分区

> 分区：将一个表或索引分解为多个更小、更可管理的部分。
>
> Mysql分区类型为水平分区，表存储在多个物理分区（最多1024）



### Mysql缓冲区

> 预读：磁盘按页读写，一次至少读一页数据(一般4K)
>
> 依据:局部性原理
>
> MysqlLRU出现的问题：
>
> - 预读失效：没有读取被缓冲的数据
>
>   预读失败的页在缓冲池LRU停留时间变短
>
>   让真正被读取的页，才挪到缓冲池LRU头部
>
>   -- 新生代+老生代：老生代存放预读，新生代存放被读取的数据页
>
> - 缓冲池污染：
>
>   大量缓存数据被替换
>
>   --老生代停留时间窗口：被访问还要有停留时间T
>
> ##### change buffer:辅助索引且不唯一
>
> > 思想，写操作较多时，把更改留在内存中，只有读取该数据时才将修改加入磁盘
> >
> > 在更新表数据时，将修改放在内存中的changebuffer中，同时写入redo log，redo log满？写脏页flush到磁盘。
> >
> > 读取该页时，执行purge操作(唯一索引不用，因为需要找读取数据页到内存来判断是否有冲突)



### binlog/redolog/undolog

> **binlog**:一个无限大小，**“追加写”**的日志文件，记录的是逻辑日志——“给 ID=2 这一行的 c 字段加1”，保留全量日志，每次commit记录------------主从复制/数据恢复
>
> 刷盘时机：
>
> > - 0：不去强制要求，由系统自行判断何时写入磁盘；
> > - 1：每次 `commit `的时候都要将 `binlog `写入磁盘；
> > - N：每N个事务，才会将 `binlog `写入磁盘。
>
> redolog:一个固定大小，**“循环写”**的日志文件，记录的是物理日志——“在某个数据页上做了某个修改”，保留未刷盘日志，记录每个执行的sql语句---------crash-safe
>
> undolog:原子性，记录DML语句相反操作
>
> **binlog和redolog一致性问题**:redo log记录事务Prepare，bin log写入并持久化(写入文件系统缓存，再调用fsyn()将其写入磁盘)、redo log增加commit 标签



### 两段提交2PC

>准备阶段：刷新redolog并缓存
>
>提交阶段：binlog写入并持久化，redolog增加commit标签



### 两段加锁2PL

> 一致性C和隔离性I
>
> 何时加锁：记录更新或者(select for update/lock in share model)，对记录加锁(共享锁、排他锁、意向锁、gap\nextkey)
>
> **S(trict)2PL**：[内容参考](https://segmentfault.com/a/1190000038163191)
>
> > 在事务中只有提交或者回滚时才是解锁阶段，其余时间为加锁阶段
> >
> > 把最热点的记录放在事务最后，较少rt时间，但是要注意死锁的情况



### MySQL主从基本原理

> master节点记录binlog并同步给slave节点
>
> ![image-20211026211925879](C:\Users\wywfd\AppData\Roaming\Typora\typora-user-images\image-20211026211925879.png)
>
> 三个线程:
>
> > - 主节点上的log dump thread
> > - I/O thread
> > - SQL thread



### MySQL 优化

> - 走索引时不查询值为null的列
> - 避免回表查询:先查普通索引获得主键值再查主索引
> - 索引字段若为字符串尽量保证选择性的情况下减少字段长度
> - 函数或者通配符都会使索引失效
> - 覆盖索引
> - like通配符匹配时注意不能使用"%A"的情况
>
> 联合索引第一列精确匹配其他列范围匹配：ref



### MVCC

> Multiversion Cuncurrency Control
>
> 保存数据在某个时间点的快照来实现并发控制
>
> 保存数据的历史版本，通过对数据行的多个版本管理来实现数据库的并发控制，只能读取已提交的快照
>
> 优点：避免了加锁操作，开销更低
>
> 系统版本号和事务版本号和删除版本号
>
> **乐观和悲观并发控制**:
>
> > - mvcc让读写互不阻塞：
> >
> >   读写锁，可以实现读读并发，数据多版本并发控制，可以实现读写并发
> >
> > - 降低了死锁的概率：
> >
> >   InnoDB的MVCC采用了乐观锁的方式，读取数据时不加锁，写操作加行锁（行锁的变种）
>
> `ReadViews`：主要包含了当前系统未提交的事务列表 TRX_IDs {TRX_ID_1, TRX_ID_2, ...}，还有该列表的最小值 TRX_ID_MIN 和 TRX_ID_MAX
>
> 在进行 SELECT 操作时，根据数据行快照的 TRX_ID 与 TRX_ID_MIN 和 TRX_ID_MAX 之间的关系，从而判断数据行快照是否可以使用：
>
> - TRX_ID < TRX_ID_MIN，表示该数据行快照时在当前所有未提交事务之前进行更改的，因此可以使用。
> - TRX_ID > TRX_ID_MAX，表示该数据行快照是在事务启动之后被更改的，因此不可使用。
> - TRX_ID_MIN <= TRX_ID <= TRX_ID_MAX，需要根据隔离级别再进行判断：
>   - 提交读：如果 TRX_ID 在 TRX_IDs 列表中，表示该数据行快照对应的事务还未提交，则该快照不可使用。否则表示已经提交，可以使用。
>   - 可重复读：都不可以使用。因为如果可以使用的话，那么其它事务也可以读到这个数据行快照并进行修改，那么当前事务再去读这个数据行得到的值就会发生改变，也就是出现了不可重复读问题。
>
> 在数据行快照不可使用的情况下，需要沿着 Undo Log 的回滚指针 ROLL_PTR 找到下一个快照，再进行上面的判断。
>
> `SELECT`：
>
> 1. InnoDB只查找版本早于当前事务版本的数据行，这样可以**确保事务读取的行要么是在开始事务之前已经存在要么是事务自身插入或者修改过的**，在事务开始之后才插入的行，事务不会看到。
>
> 2. 行的删除版本号要么未定义，要么大于当前事务版本号，这样可以**确保事务读取到的行在事务开始之前未被删除**，在事务开始之前就已经过期的数据行，该事务也不会看到。
>
> `INSERT` `DELETE`：当前系统版本号作为数据行快照创建/删除版本号
>
> **快照读**：读历史数据，select，减少加锁带来的开销
>
> **当前读**：会对数据进行修改的操作，在执行这几个操作时会读取最新的记录。
>
> ​		**为何**：假设要update一条记录，但是在另一个事务中已经delete掉这条数据并且commit了，如果update就会产生冲突，所以在update的时候需要知道最新的数据。



#### Next-Key Locks

> 解决幻影读
>
> 对索引：左闭右开，非主键或唯一索引，还会对下一个值加上GapLock
>
> 对非索引：加全表锁
>
> 
>
> ```mysql
> LOCK_MODE = X 是前开后闭区间；
> X,GAP 是前开后开区间（间隙锁）；
> X,REC_NOT_GAP 行锁。
> ```
>
> **索引上的等值查询**：
>
> - 给唯一索加锁的时候，next-key-Lock退化为行锁(record key)
> - 向右遍历且最后一个值不满足条件时，退化为gap锁
>
> **唯一索引上的范围查询**：
>
> - 会访问到不满足条件的第一个值为止，是一个BUG
>
>   ```mysql
>   mysql> begin; select * from t where id > 10 and id <= 15 for update;
>   ```
>
>   id=15 存在，会锁住到第一个不符合条件的值(15,20)
>
>   BUG已修复，不会锁住20，对非唯一索引会锁住20
>
> **加锁状态**：
>
> - INDEX_NAME：锁定索引的名称
> - LOCK_TYPE：锁的类型，对于 InnoDB，允许的值为 RECORD 行级锁 和 TABLE 表级锁。
> - LOCK_MODE：锁的类型：S, X, IS, IX, and gap locks
> - LOCK_DATA：锁关联的数据，对于 InnoDB，当 LOCK_TYPE 是 RECORD（行锁），则显示值。当锁在主键索引上时，则值是锁定记录的主键值。当锁是在辅助索引上时，则显示辅助索引的值，并附加上主键值。



## Redis

>    基于内存的数据结构存储器，可用作数据库、缓存和消息中间件
>
>    读取数据快的原因：
>
>    > - 基于内存
>    >
>    > - 单线程：Redis即将采用多线程，多线程中会使用到HashTable，多个线程竞争一把锁造成线程等待降低性能，此外还有上下文的切换
>    >
>    > - IO多路复用：保证redis在I/O操作时依然能处理socket请求，不会浪费在I/O上的时间
>    >
>    >   



>    客户端请求通过负载均衡算法（一致性Hash），分散到各个Redis服务器上
>
>    通过Redis集群，实现两个特性：
>
>    - 扩大缓存容量
>- 提升吞吐量
>    
>    键:string
>
>    值：string/hash/list/set/zset
>
>    ### 常见命令：
>
>    ```python
>select index  # 切换数据库，0~15代表16个数据库
>    keys *  # 查看当前所有的keys，这个在生产环境下不要使用 
>    keys pattern # 查找键，支持正则，常用的有  *(匹配0个或多个) ?(匹配一个) [a-z] [abcd] 
>    exists key # 查看这个key是否存在 
>    type key # 查看key的类型
>    ttl key # 查看有效时间,指的是还剩余的有效时间，如果过期，有效时间置为-2；如果设置为永久有效，有效时间为-1. 
>    dbsize # 查看数据库中所有的键值对的数目 
>    randomkey # 随机返回数据库里的一个key 
>    rename key1 key2 # 重命名key
>    flushdb # 清空当前选择的数据库 
>    flushall # 清库该redis实例所有的数据库 
>    expire key seconds # 为键值对设置过期时间
>    client list # 查看当前所有的客户端 
>    # 同步磁盘 
>    save  # 会立即阻塞所有的客户端请求，开始同步rdb文件 
>    gbsave  # 异步保存rdb文件
>    ```
>    
>    ### 操作string类型
>
>    > **增**：
>>
>    > ```python
>    > set key value  # 设置键值对，永久保存
>    > 
>    > setex key 时间 value  # 设置有过期时间的键值对，过期自动删除
>    > 
>    > mset key value key value ...# 设置多个键值对
>    > 
>    > msetnx key value key value# 设置多个不存在的键值对，存在则失败
>    > 
>    > setnx key value   # 如果键存在，设置失败
>    > 
>    > setrange key offset value# 字符串中字符替换
>    > ```
>    >
>    > **删**：
>    >
>    > ```python
>    > del key key # 删除一个或多个键值对
>    > ```
>    >
>    > **改**：
>    >
>    > ```python
>    > # 对于value是数值的情况，可以运算；如果不是数字会报错；
>    > incr key   # 对value加1
>    > 
>    > incrby key num  # 对value加一个整数，可以是负数，但不可以是小数
>    > 
>    > incrbyfloat key num  # 对value加一个浮点数，可以是负数
>    > 
>    > decr key   # 对value减少1
>    > 
>    > decrby key num  # 对value减一个整数，可以是负数，但不可以是小数
>    > 
>    > append key value  # 对原来的key的值进行字符串拼接
>    > ```
>    >
>    > **查**：
>    >
>    > ```python
>    > get key# 获取值
>    > getrange key start end# 获取子字符串
>    > strlen key   # 获取值得长度
>    > ```
>    >
>    



### Redis常见问题

#### 数据结构

[参考资料](https://redis.io/topics/data-types-intro)

#### 剔除策略LRU

[参考资料](https://redis.io/topics/lru-cache)

#### 负载均衡

[参考资料](https://redis.io/topics/partitioning)

#### Presharding

> 数据分片分区[参考资料](https://redis.io/topics/partitioning#presharding)

#### 数据持久化

[参考资料](https://redis.io/topics/persistence)

#### 数据同步

> 主从复制P [参考资料](https://redis.io/topics/replication)

#### 缓存模式

> 只读缓存：修改直接写入数据库，然后设置缓存失效
>
> 读写缓存：读写都在缓存中进行，会出现宕机故障，导致数据丢失，缓存写回数据库分两种方式：
>
> - 同步：访问性能偏低，注重数据可靠性，有双写不一致问题
>   - Read-Through
>   - Write-Through
> - 异步：有数据丢失风险，注重低延时
>   - Write-Behind模式



#### 分布式部署

三种部署模式：主从，哨兵，集群



> ​		**主从模式**：有数据备份，保证一定的可用性，一旦主节点出现故障，需要手动将一个从节点晋升为主节点，同时需要修改应用方的主节点地址，还需要命令其他从节点去复制新的主节点，整个过程需要人工干预
>
> ​		**哨兵模式**：自动化的故障恢复，保证高可用
>
> ​		每个Sentinel以 每秒钟 一次的频率，向它**所有**的 **主服务器**、**从服务器** 以及其他Sentinel**实例** 发送一个PING 命令
>
> ​		主节点超时：主观下线->客观下线
>
> ​		缺点：很难支持在线扩容
>
> ​	**集群模式**
>
> - Redis集群采用一致性哈希槽的方式将集群中每个主节点都分配一定的哈希槽，对写入的数据进行哈希后分配到某个主节点进行存储。
> - 集群使用公式（CRC16 key）& 16384计算键key数据那个槽。
> - 16384个slot均匀分布在各个节点上。
> - 集群中每个主节点将承担一部分槽点的维护，而槽点中存储着数据，每个主节点都有至少一个从节点用于高可用。
>
> 
>
> **一致性hash**
>
> 传统哈希算法局限性：
>
> 1. 节点减少，原有的节点hash值需要重新计算
> 2. 节点增加，服务节点扩容，需要重新计算hash值
>
> **优点**：
>
> - 可扩展性。一致性哈希算法保证了增加或减少服务器时，数据存储的改变最少，相比传统哈希算法大大节省了数据移动的开销 。
>
> - 更好地适应数据的快速增长。采用一致性哈希算法分布数据，当数据不断增长时，部分虚拟节点中可能包含很多数据、造成数据在虚拟节点上分布不均衡，此时可以将包含数据多的虚拟节点分裂，这种分裂仅仅是将原有的虚拟节点一分为二、不需要对全部的数据进行重新哈希和划分。
>
>   ​		虚拟节点分裂后，如果物理服务器的负载仍然不均衡，只需在服务器之间调整部分虚拟节点的存储分布。这样可以随数据的增长而动态的扩展物理服务器的数量，且代价远比传统哈希算法重新分布所有数据要小很多。
>
> **原理**：一致性哈希环
>
> 对象放入哈希环
>
> 服务器放入哈希环
>
> 为对象选择服务器
>
> 以上三点之解决了节点增减的问题，并未解决负载均衡：
>
> **虚拟节点**:一个物理节点对应多个虚拟节点，对象先找到虚拟节点在找到物理节点

